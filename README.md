# ğŸ¤– MCP AI Agent System

**2025å¹´æœ€å…ˆç«¯ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**ã‚·ã‚¹ãƒ†ãƒ 

LINE â†’ Gemini â†’ ã¯ã¦ãªãƒ–ãƒ­ã‚° è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ 

## ğŸš€ ç‰¹å¾´

### ğŸ”¥ 2025å¹´ãƒˆãƒ¬ãƒ³ãƒ‰å®Œå…¨å¯¾å¿œ
- âœ… **Model Context Protocol (MCP)** æ¨™æº–æº–æ‹ 
- âœ… **LangGraph** ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼  
- âœ… **FastMCP** æœ€æ–°å®Ÿè£…
- âœ… **Agent-to-Agent** é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«æº–å‚™æ¸ˆã¿

### ğŸ¯ ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦
```
ğŸ¤– MCP AI Agent System
â”œâ”€â”€ ğŸ”§ MCP Servers (FastMCP)
â”‚   â”œâ”€â”€ LINE MCP Server (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡ãƒ»é€ä¿¡)
â”‚   â”œâ”€â”€ Gemini MCP Server (AI ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ)
â”‚   â””â”€â”€ Hatena MCP Server (ãƒ–ãƒ­ã‚°æŠ•ç¨¿)
â”œâ”€â”€ ğŸ§  AI Agent Core (LangGraph)
â”‚   â”œâ”€â”€ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åˆ†æãƒãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ ã‚¿ã‚¹ã‚¯ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆãƒãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ è¨˜äº‹æŠ•ç¨¿ãƒãƒ¼ãƒ‰
â”‚   â””â”€â”€ é€šçŸ¥ãƒãƒ¼ãƒ‰
â””â”€â”€ ğŸŒ Flask API
    â”œâ”€â”€ LINE Webhookå—ä¿¡
    â”œâ”€â”€ AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
    â””â”€â”€ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
```

## Project Structure Overview

This project contains two main application entry points:

1.  **Main Application (`main.py`)**:
    *   This is the primary Flask application for the LINE to Hatena blog automation.
    *   It handles incoming LINE webhooks using an enhanced batch processing system (`src/routes/webhook_enhanced.py`). This system collects messages (text, images, videos), processes them in batches per user, uses Gemini for content analysis and generation, integrates with Imgur for image hosting, and posts articles to Hatena.
    *   It exposes REST APIs for accessing articles, messages, and other functionalities (`src/routes/api.py`).
    *   Database interaction (SQLAlchemy with `src.database.py`) is central to this application for storing messages, articles, and batch processing states.

2.  **LangGraph Application (`langgraph_main.py`)**:
    *   This is a separate Flask application dedicated to showcasing an alternative processing pipeline using LangGraph agents.
    *   It handles LINE webhooks via `src/routes/langgraph_routes.py` and processes messages using a more complex, stateful agent defined in `src/langgraph_agents/`.
    *   This system is geared towards more advanced, multi-step agentic workflows and leverages the LangGraph library.

The choice of which application to run depends on the desired processing model. The `main.py` application provides a robust batch-oriented system, while `langgraph_main.py` offers a more flexible agent-based approach.

## ğŸ›  ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. ç’°å¢ƒæº–å‚™
```bash
git clone https://github.com/chnmotoTmz/mcp-ai-agent-system.git
cd line-gemini-hatena-integration
chmod +x setup_mcp.sh
./setup_mcp.sh
```

### 2. ç’°å¢ƒå¤‰æ•°è¨­å®š
```bash
cp .env.example .env
# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¦å¿…è¦ãªç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
```

### 3. ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•
```bash
python3 start_mcp_system.py
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆæ–¹æ³•

### AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
```bash
curl -X POST http://localhost:8084/api/webhook/test \
  -H 'Content-Type: application/json' \
  -d '{"message": "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆã§ã™", "user_id": "test_user"}'
```

### ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
```bash
curl http://localhost:8084/status
```

## ğŸ“‹ å¿…è¦ãªç’°å¢ƒå¤‰æ•°

```env
# LINE Botè¨­å®š
LINE_CHANNEL_ACCESS_TOKEN=your_line_channel_access_token
LINE_CHANNEL_SECRET=your_line_channel_secret

# Gemini APIè¨­å®š
GEMINI_API_KEY=your_gemini_api_key

# ã¯ã¦ãªãƒ–ãƒ­ã‚°è¨­å®š
HATENA_USER_ID=your_hatena_user_id
HATENA_BLOG_ID=your_hatena_blog_id
HATENA_API_KEY=your_hatena_api_key

# ãã®ä»–
SECRET_KEY=your_secret_key
PORT=8084
```

## ğŸ— ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### MCP Servers
- **LINE MCP Server** (`src/mcp_servers/line_server_fastmcp.py`)
  - LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€å—ä¿¡
  - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†
  - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´å–å¾—

- **Gemini MCP Server** (`src/mcp_servers/gemini_server_fastmcp.py`)
  - AIã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
  - ç”»åƒåˆ†æ
  - ãƒ–ãƒ­ã‚°è¨˜äº‹ä½œæˆ

- **Hatena MCP Server** (`src/mcp_servers/hatena_server_fastmcp.py`)
  - ã¯ã¦ãªãƒ–ãƒ­ã‚°è¨˜äº‹æŠ•ç¨¿
  - è¨˜äº‹ç®¡ç†
  - ãƒ–ãƒ­ã‚°çµ±è¨ˆå–å¾—

### AI/Agent Components

The system employs AI for content generation and processing in two main ways:

1.  **Primary Application (`main.py`)**:
    *   The LINE message processing workflow in `src/routes/webhook_enhanced.py` directly utilizes `src/services/gemini_service.py` for:
        *   Analyzing images and generating textual descriptions.
        *   Generating blog content based on collected user messages (text and image analyses).
        *   Generating article titles.
    *   This approach is service-oriented, with direct calls to the Gemini service for specific AI tasks within the batch processing flow.

2.  **LangGraph Application (`langgraph_main.py`)**:
    *   This application uses a dedicated LangGraph agent defined in `src/langgraph_agents/agent.py`.
    *   This agent orchestrates a more complex, stateful workflow involving multiple steps (nodes in the graph) which can include calls to MCP servers (like Gemini, Hatena, etc.) for various AI and publishing tasks.
    *   This architecture is designed for building sophisticated, multi-actor AI systems.

## ğŸ”§ é–‹ç™ºãƒ»æ‹¡å¼µ

### æ–°ã—ã„MCPã‚µãƒ¼ãƒãƒ¼ã®è¿½åŠ 

1. **ã‚µãƒ¼ãƒãƒ¼ä½œæˆ**
```python
from mcp.server.fastmcp import FastMCP

new_mcp = FastMCP("New Service")

@new_mcp.tool()
async def new_tool(param: str) -> dict:
    """æ–°ã—ã„ãƒ„ãƒ¼ãƒ«ã®å®Ÿè£…"""
    return {"result": f"å‡¦ç†çµæœ: {param}"}
```

2. **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®çµ±åˆ**
```python
# ContentCreationAgentã®MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šã«è¿½åŠ 
"new_service": {
    "command": "python",
    "args": ["/path/to/new_server.py"],
    "transport": "stdio"
}
```

### æ–°ã—ã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¿½åŠ 

æ–°ã—ã„å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã€Agent-to-Agenté€šä¿¡ã§ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯èƒ½ï¼š

```python
class SpecializedAgent:
    """å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    async def collaborate_with(self, other_agent):
        """ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®å”èª¿å‡¦ç†"""
        pass
```

## ğŸ“ˆ ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### Phase 2: è¿½åŠ MCPã‚µãƒ¼ãƒãƒ¼
- [ ] NotebookLM MCP Server (ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè§£æ)
- [ ] Whisper MCP Server (éŸ³å£°æ–‡å­—èµ·ã“ã—)
- [ ] YouTube MCP Server (å‹•ç”»ä½œæˆãƒ»æŠ•ç¨¿)
- [ ] Analytics MCP Server (åˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆ)

### Phase 3: ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¼·åŒ–
- [ ] Agent-to-Agent (A2A) ãƒ—ãƒ­ãƒˆã‚³ãƒ«å®Ÿè£…
- [ ] ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹
- [ ] å‹•çš„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”Ÿæˆ
- [ ] å­¦ç¿’ãƒ»é€²åŒ–æ©Ÿèƒ½

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License - è©³ç´°ã¯ [LICENSE](LICENSE) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§

## ğŸ™ è¬è¾

- [Model Context Protocol](https://modelcontextprotocol.io/) - Anthropic
- [LangGraph](https://langchain-ai.github.io/langgraph/) - LangChain AI
- [FastMCP](https://github.com/jlowin/fastmcp) - Marvin AI

---

**ğŸ¯ 2025å¹´ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ™‚ä»£ã®æ¨™æº–ã‚·ã‚¹ãƒ†ãƒ **

Made with â¤ï¸ for the AI Agent Revolution